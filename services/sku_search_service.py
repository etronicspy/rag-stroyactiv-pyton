"""
SKU Search Service for RAG Construction Materials API

–î–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –ø–æ–∏—Å–∫ SKU –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤:
1. –≠–¢–ê–ü 1: –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É embedding
2. –≠–¢–ê–ü 2: –¢–æ—á–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ normalized_unit (—Å—Ç—Ä–æ–≥–æ) –∏ normalized_color (–≥–∏–±–∫–æ –¥–ª—è None)

–°–æ–≥–ª–∞—Å–Ω–æ –¥–∏–∞–≥—Ä–∞–º–º–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≠–¢–ê–ü 6.
"""

import asyncio
import hashlib
import logging
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from functools import lru_cache

from core.config.base import Settings
from core.database.interfaces import IVectorDatabase
from core.schemas.pipeline_models import (
    SKUSearchRequest,
    SKUSearchResponse,
    SKUSearchCandidate,
    SKUSearchConfig
)
from services.combined_embedding_service import get_combined_embedding_service

logger = logging.getLogger(__name__)


class SKUSearchService:
    """
    –î–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –ø–æ–∏—Å–∫ SKU –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
    
    –õ–û–ì–ò–ö–ê –ü–û–ò–°–ö–ê:
    1. –≠–¢–ê–ü 1: –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ø–æ similarity_threshold
    2. –≠–¢–ê–ü 2: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤:
       - normalized_unit: –°–¢–†–û–ì–û–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ 
       - normalized_color: –ì–ò–ë–ö–ê–Ø –ª–æ–≥–∏–∫–∞ (None –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ª—é–±–æ–π —Ü–≤–µ—Ç)
    3. –†–ï–ó–£–õ–¨–¢–ê–¢: SKU –ø–µ—Ä–≤–æ–≥–æ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É —Ä–µ–π—Ç–∏–Ω–≥—É
    """
    
    def __init__(
        self, 
        vector_db: Optional[IVectorDatabase] = None,
        config: Optional[SKUSearchConfig] = None
    ):
        """
        Initialize SKU Search Service
        
        Args:
            vector_db: Vector database instance for material search
            config: Service configuration
        """
        self.settings = Settings()
        self.config = config or SKUSearchConfig()
        self.logger = logger
        
        # Initialize vector database
        if vector_db is None:
            try:
                # Lazy import to avoid circular imports
                from core.database.factories import DatabaseFactory
                self.vector_db = DatabaseFactory.create_vector_database()
                self.logger.info("‚úÖ Vector database initialized for SKU search")
            except Exception as e:
                self.logger.error(f"‚ùå Failed to initialize vector database: {e}")
                self.vector_db = None
        else:
            self.vector_db = vector_db
        
        # Get combined embedding service
        self.embedding_service = get_combined_embedding_service()
        
        # In-memory cache for search results
        self.search_cache: Dict[str, Tuple[SKUSearchResponse, datetime]] = {}
        
        self.logger.info("SKU Search Service initialized")
    
    async def find_sku_by_material_data(
        self,
        material_name: str,
        unit: str,
        normalized_color: Optional[str] = None,  # Kept for compatibility but ignored
        material_embedding: Optional[List[float]] = None,
        similarity_threshold: Optional[float] = None,
        max_candidates: Optional[int] = None
    ) -> SKUSearchResponse:
        """
        Main method: Find SKU using two-phase search (now via centralized fallback manager)
        """
        from core.database.factories import get_fallback_manager, AllDatabasesUnavailableError
        start_time = time.time()
        threshold = similarity_threshold or self.config.similarity_threshold
        max_cands = max_candidates or self.config.max_candidates
        self.logger.info(f"üîç Starting SKU search for: {material_name} [{unit}]")
        # Check cache first
        if self.config.cache_enabled:
            cache_key = self._generate_cache_key(material_name, unit, None, threshold)
            cached_result = self._get_cached_result(cache_key)
            if cached_result:
                self.logger.debug(f"üìã Cache hit for SKU search: {material_name}")
                return cached_result
        fallback_manager = get_fallback_manager()
        try:
            response = await fallback_manager.find_sku_by_material_data(
                material_name=material_name,
                unit=unit,
                normalized_color=normalized_color,
                material_embedding=material_embedding,
                similarity_threshold=threshold,
                max_candidates=max_cands
            )
            # Cache result
            if self.config.cache_enabled:
                self._cache_result(cache_key, response)
            return response
        except AllDatabasesUnavailableError as e:
            self.logger.error(f"All databases unavailable for SKU search: {e.errors}")
            raise
    
    async def _phase1_vector_search(
        self, 
        query_embedding: List[float], 
        similarity_threshold: float,
        max_candidates: int
    ) -> List[SKUSearchCandidate]:
        """Phase 1: Vector search for similar materials in reference collection"""
        try:
            # Perform vector search
            search_results = await self.vector_db.search(
                collection_name=self.config.reference_collection,
                query_vector=query_embedding,
                limit=max_candidates * 2,  # Get more results for threshold filtering
                filter_conditions=None
            )
            
            # Filter by similarity threshold and convert to candidates
            candidates = []
            for result in search_results:
                # Filter by similarity threshold
                if result["score"] >= similarity_threshold:
                    payload = result.get("payload", {})
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ Qdrant
                    unit = payload.get("unit", "")
                    color = payload.get("normalized_color") or payload.get("color")  # –ú–æ–∂–µ—Ç –Ω–µ –±—ã—Ç—å
                    
                    candidate = SKUSearchCandidate(
                        material_id=result["id"],
                        sku=payload.get("sku", ""),
                        name=payload.get("name", ""),  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: 'name' –≤–º–µ—Å—Ç–æ 'material_name'
                        unit=unit,  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: 'unit' –≤–º–µ—Å—Ç–æ 'normalized_unit'
                        description=payload.get("description", ""),  # –î–æ–±–∞–≤–ª–µ–Ω–æ: –Ω–æ–≤–æ–µ –ø–æ–ª–µ
                        similarity_score=result["score"],
                        unit_match=False,  # Will be evaluated in Phase 2
                        color_match=False,  # Will be evaluated in Phase 2  
                        overall_match=False  # Will be evaluated in Phase 2
                    )
                    candidates.append(candidate)
            
            # Sort by similarity score (highest first) and limit
            candidates.sort(key=lambda x: x.similarity_score, reverse=True)
            candidates = candidates[:max_candidates]
            
            logger.debug(f"Phase 1: Found {len(candidates)} candidates with similarity >= {similarity_threshold}")
            return candidates
            
        except Exception as e:
            logger.error(f"Phase 1 vector search failed: {e}")
            return []
    
    def _phase2_attribute_filtering(
        self,
        candidates: List[SKUSearchCandidate],
        unit: str,
        normalized_color: Optional[str]
    ) -> List[SKUSearchCandidate]:
        """
        –≠–¢–ê–ü 2: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ –∞—Ç—Ä–∏–±—É—Ç–∞–º (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ —Ä–µ–∞–ª—å–Ω—É—é –ë–î)
        
        –õ–û–ì–ò–ö–ê –§–ò–õ–¨–¢–†–ê–¶–ò–ò:
        1. unit: –°–¢–†–û–ì–û–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –ø–æ–ª–µ–º 'unit' –∏–∑ –ë–î (—à—Ç == —à—Ç, —à—Ç != –∫–≥)
        2. color: –û–¢–ö–õ–Æ–ß–ï–ù–ê (–ø–æ–ª–µ 'normalized_color' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –ë–î)
        
        Args:
            candidates: –ö–∞–Ω–¥–∏–¥–∞—Ç—ã –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
            unit: –¢—Ä–µ–±—É–µ–º–∞—è –µ–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è (–ø–æ–ª–µ 'unit' –∏–∑ –ë–î)
            normalized_color: –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)
            
        Returns:
            –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã
        """
        matching_candidates = []
        
        for candidate in candidates:
            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è (–°–¢–†–û–ì–ê–Ø) - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–µ 'unit' –∏–∑ –ë–î
            unit_match = self._check_unit_match(candidate.unit, unit)
            
            # 2. –¶–≤–µ—Ç–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞ (–ø–æ–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –ë–î)
            color_match = True  # Always pass since no color field in DB
            
            # 3. –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—Ç–æ–ª—å–∫–æ –ø–æ –µ–¥–∏–Ω–∏—Ü–µ)
            overall_match = unit_match
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏
            candidate.unit_match = unit_match
            candidate.color_match = color_match  
            candidate.overall_match = overall_match
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
            if overall_match:
                matching_candidates.append(candidate)
            
            logger.debug(
                f"üîç Candidate {candidate.name}: "
                f"unit={unit_match} ({candidate.unit} vs {unit}), "
                f"overall={overall_match}"
            )
        
        return matching_candidates
    
    def _check_unit_match(self, candidate_unit: str, required_unit: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
        
        Args:
            candidate_unit: –ï–¥–∏–Ω–∏—Ü–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
            required_unit: –¢—Ä–µ–±—É–µ–º–∞—è –µ–¥–∏–Ω–∏—Ü–∞
            
        Returns:
            True –µ—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç (—Å —É—á–µ—Ç–æ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)
        """
        if not candidate_unit or not required_unit:
            return False
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ–±–µ –µ–¥–∏–Ω–∏—Ü—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        normalized_candidate = self._normalize_unit_for_comparison(candidate_unit)
        normalized_required = self._normalize_unit_for_comparison(required_unit)
        
        # –°—Ç—Ä–æ–≥–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü
        match = normalized_candidate == normalized_required
        
        logger.debug(f"Unit comparison: '{candidate_unit}' ({normalized_candidate}) vs '{required_unit}' ({normalized_required}) = {match}")
        
        return match
    
    def _normalize_unit_for_comparison(self, unit: str) -> str:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        
        Args:
            unit: –ò—Å—Ö–æ–¥–Ω–∞—è –µ–¥–∏–Ω–∏—Ü–∞
            
        Returns:
            –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –µ–¥–∏–Ω–∏—Ü–∞
        """
        if not unit:
            return ""
        
        unit_clean = unit.lower().strip()
        
        # –°–ª–æ–≤–∞—Ä—å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –µ–¥–∏–Ω–∏—Ü
        unit_mappings = {
            # –í–µ—Å
            "–∫–≥": "–∫–≥",
            "–∫–∏–ª–æ–≥—Ä–∞–º–º": "–∫–≥", 
            "–∫–∏–ª–æ–≥—Ä–∞–º–º—ã": "–∫–≥",
            "–∫–∏–ª–æ–≥—Ä–∞–º–º–æ–≤": "–∫–≥",
            "kg": "–∫–≥",
            "–∫–∏–ª–æ": "–∫–≥",
            
            # –û–±—ä–µ–º  
            "–º¬≥": "–º¬≥",
            "–∫—É–±": "–º¬≥",
            "–∫—É–±–æ–º–µ—Ç—Ä": "–º¬≥",
            "–∫—É–±–æ–º–µ—Ç—Ä—ã": "–º¬≥", 
            "–∫—É–±–æ–º–µ—Ç—Ä–æ–≤": "–º¬≥",
            "–º3": "–º¬≥",
            "–∫—É–±.–º": "–º¬≥",
            "–∫—É–±–∏—á–µ—Å–∫–∏–π –º–µ—Ç—Ä": "–º¬≥",
            
            # –ü–ª–æ—â–∞–¥—å
            "–º¬≤": "–º¬≤",
            "–∫–≤.–º": "–º¬≤",
            "–º2": "–º¬≤",
            "–∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π –º–µ—Ç—Ä": "–º¬≤",
            "–∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ –º–µ—Ç—Ä—ã": "–º¬≤",
            "–∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö –º–µ—Ç—Ä–æ–≤": "–º¬≤",
            
            # –®—Ç—É–∫–∏
            "—à—Ç": "—à—Ç",
            "—à—Ç—É–∫–∞": "—à—Ç",
            "—à—Ç—É–∫–∏": "—à—Ç",
            "—à—Ç—É–∫": "—à—Ç",
            "pcs": "—à—Ç",
            "pc": "—à—Ç",
            
            # –ú–µ—Ç—Ä—ã
            "–º": "–º",
            "–º–µ—Ç—Ä": "–º",
            "–º–µ—Ç—Ä—ã": "–º",
            "–º–µ—Ç—Ä–æ–≤": "–º",
            "meter": "–º",
            
            # –õ–∏—Ç—Ä—ã
            "–ª": "–ª",
            "–ª–∏—Ç—Ä": "–ª",
            "–ª–∏—Ç—Ä—ã": "–ª",
            "–ª–∏—Ç—Ä–æ–≤": "–ª",
            "liter": "–ª",
            "l": "–ª"
        }
        
        return unit_mappings.get(unit_clean, unit_clean)
    
    def _check_color_compatibility(
        self, 
        candidate_color: Optional[str], 
        required_color: Optional[str]
    ) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Ü–≤–µ—Ç–æ–≤ (–ì–ò–ë–ö–ê–Ø –õ–û–ì–ò–ö–ê)
        
        –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –õ–û–ì–ò–ö–ê:
        - –ï—Å–ª–∏ required_color is None/null -> –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –õ–Æ–ë–û–ô —Ü–≤–µ—Ç (return True)
        - –ï—Å–ª–∏ required_color —É–∫–∞–∑–∞–Ω -> —Ç—Ä–µ–±—É–µ—Ç –¢–û–ß–ù–û–ì–û —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        
        Args:
            candidate_color: –¶–≤–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
            required_color: –¢—Ä–µ–±—É–µ–º—ã–π —Ü–≤–µ—Ç
            
        Returns:
            True –µ—Å–ª–∏ —Ü–≤–µ—Ç–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã
        """
        if required_color is None or required_color == "null":
            # None –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ª—é–±–æ–π —Ü–≤–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
            return True
        
        if candidate_color is None:
            # –¢—Ä–µ–±—É–µ—Ç—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ü–≤–µ—Ç, –Ω–æ —É –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –µ–≥–æ –Ω–µ—Ç
            return False
        
        # –°—Ç—Ä–æ–≥–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ü–≤–µ—Ç–æ–≤
        return candidate_color.lower().strip() == required_color.lower().strip()
    
    def _select_best_match(self, candidates: List[SKUSearchCandidate]) -> Optional[SKUSearchCandidate]:
        """
        –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É —Ä–µ–π—Ç–∏–Ω–≥—É
        
        Args:
            candidates: –°–ø–∏—Å–æ–∫ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
            
        Returns:
            –õ—É—á—à–∏–π –∫–∞–Ω–¥–∏–¥–∞—Ç –∏–ª–∏ None
        """
        if not candidates:
            return None
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ similarity_score (—É–±—ã–≤–∞–Ω–∏–µ) –∏ –≤—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤–æ–≥–æ
        best_candidate = max(candidates, key=lambda c: c.similarity_score)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ SKU
        if not best_candidate.sku:
            self.logger.warning(f"Best candidate has no SKU: {best_candidate.name}")  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: 'name' –≤–º–µ—Å—Ç–æ 'material_name'
            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å SKU
            candidates_with_sku = [c for c in candidates if c.sku]
            if candidates_with_sku:
                best_candidate = max(candidates_with_sku, key=lambda c: c.similarity_score)
            else:
                return None
        
        return best_candidate
    
    def _convert_search_result_to_candidate(self, search_result: Dict[str, Any]) -> Optional[SKUSearchCandidate]:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ —Ä–µ–∞–ª—å–Ω—É—é –ë–î)
        
        Args:
            search_result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ Qdrant
            
        Returns:
            SKUSearchCandidate –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            payload = search_result.get("payload", {})
            
            # –û—Ç–ª–∞–¥–æ—á–Ω—ã–π –≤—ã–≤–æ–¥
            self.logger.debug(f"Converting search result: {search_result}")
            self.logger.debug(f"Payload keys: {list(payload.keys())}")
            self.logger.debug(f"Name: {payload.get('name')}, Unit: {payload.get('unit')}")
            
            return SKUSearchCandidate(
                material_id=str(search_result.get("id")),
                sku=payload.get("sku"),
                name=payload.get("name", "UNKNOWN"),  # Fallback to avoid empty string
                unit=payload.get("unit", "UNKNOWN"),  # Fallback to avoid empty string
                description=payload.get("description", ""),  # Using 'description' field from DB
                similarity_score=float(search_result.get("score", 0.0)),
                unit_match=False,  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –≤ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                color_match=False,  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –≤ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏  
                overall_match=False  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –≤ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            )
            
        except Exception as e:
            self.logger.error(f"Failed to convert search result: {e}")
            self.logger.error(f"Search result data: {search_result}")
            return None
    
    def _generate_cache_key(
        self,
        material_name: str,
        normalized_unit: str,
        normalized_color: Optional[str],
        similarity_threshold: float
    ) -> str:
        """Generate cache key for search request"""
        cache_data = f"{material_name}_{normalized_unit}_{normalized_color or 'none'}_{similarity_threshold}"
        return hashlib.md5(cache_data.encode()).hexdigest()
    
    def _get_cached_result(self, cache_key: str) -> Optional[SKUSearchResponse]:
        """Get cached search result if not expired"""
        if cache_key not in self.search_cache:
            return None
        
        result, cached_at = self.search_cache[cache_key]
        if datetime.utcnow() - cached_at > timedelta(seconds=self.config.cache_ttl):
            del self.search_cache[cache_key]
            return None
        
        return result
    
    def _cache_result(self, cache_key: str, response: SKUSearchResponse) -> None:
        """Cache search result"""
        # Simple cache size management
        if len(self.search_cache) > 1000:  # Max 1000 cached results
            # Remove oldest 20%
            sorted_cache = sorted(
                self.search_cache.items(),
                key=lambda x: x[1][1]  # Sort by timestamp
            )
            for key, _ in sorted_cache[:200]:
                del self.search_cache[key]
        
        self.search_cache[cache_key] = (response, datetime.utcnow())
    
    def _create_error_response(self, error_message: str, start_time: float) -> SKUSearchResponse:
        """Create error response"""
        return SKUSearchResponse(
            found_sku=None,
            search_successful=False,
            candidates_evaluated=0,
            matching_candidates=0,
            best_match=None,
            search_method="error",
            processing_time=time.time() - start_time,
            error_message=error_message
        )
    
    async def test_connection(self) -> bool:
        """Test vector database and embedding service connection
        
        Returns:
            True if both connections work
        """
        try:
            # Test vector database connection
            health_status = await self.vector_db.health_check()
            vector_db_ok = health_status.get("status") == "healthy"
            
            # Test embedding service connection  
            embedding_ok = await self.embedding_service.test_connection()
            
            if vector_db_ok and embedding_ok:
                logger.info("‚úÖ All connections working properly")
                return True
            else:
                logger.error(f"‚ùå Connection test failed - Vector DB: {vector_db_ok}, Embeddings: {embedding_ok}")
                return False
                
        except Exception as e:
            logger.error(f"Connection test failed: {e}")
            return False
    
    def get_statistics(self) -> Dict[str, Any]:
        """Get service statistics"""
        return {
            "cache_size": len(self.search_cache),
            "config": self.config.model_dump(),
            "vector_db_available": self.vector_db is not None
        }


# Singleton pattern for service
_sku_search_service_instance: Optional[SKUSearchService] = None


@lru_cache(maxsize=1)
def get_sku_search_service() -> SKUSearchService:
    """
    Get or create SKU Search Service singleton
    
    Returns:
        SKUSearchService instance
    """
    global _sku_search_service_instance
    
    if _sku_search_service_instance is None:
        _sku_search_service_instance = SKUSearchService()
        logger.info("‚úÖ SKU Search Service singleton created")
    
    return _sku_search_service_instance 