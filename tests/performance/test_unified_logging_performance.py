"""
ðŸš€ Performance Tests for Unified Logging System

Performance tests focusing on:
- Logger caching performance (Stage 4)
- Correlation ID optimization
- Concurrent logging performance
- End-to-end latency measurements

Author: AI Assistant
Created: 2024
"""

import pytest
import time
import uuid
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, Any

# Core imports
from core.monitoring.unified_manager import get_unified_logging_manager
from core.monitoring.context import CorrelationContext, get_correlation_id
from core.monitoring.logger import get_logger


class TestLoggerCachingPerformance:
    """ðŸš€ Logger Caching Performance Tests"""
    
    def test_logger_creation_performance(self):
        """Test performance improvement from logger caching."""
        # Measure uncached logger creation
        start_time = time.perf_counter()
        for i in range(1000):
            get_logger(f"uncached_test_{i}")
        uncached_duration = time.perf_counter() - start_time
        
        # Measure cached logger creation (same names)
        start_time = time.perf_counter()
        for i in range(1000):
            get_logger("cached_test")
        cached_duration = time.perf_counter() - start_time
        
        # Cached should be significantly faster
        performance_improvement = (uncached_duration - cached_duration) / uncached_duration * 100
        
        print(f"Uncached: {uncached_duration:.4f}s, Cached: {cached_duration:.4f}s")
        print(f"Performance improvement: {performance_improvement:.1f}%")
        
        # Should be at least some improvement
        assert performance_improvement > 0.0


class TestCorrelationIdOptimizationPerformance:
    """ðŸš€ Correlation ID Optimization Performance Tests"""
    
    def test_correlation_id_generation_performance(self):
        """Test correlation ID generation performance."""
        # Test standard UUID generation
        start_time = time.perf_counter()
        for _ in range(10000):
            str(uuid.uuid4())
        standard_duration = time.perf_counter() - start_time
        
        print(f"Standard UUID generation: {standard_duration:.4f}s for 10000 IDs")
        
        # Should be reasonably fast
        assert standard_duration < 1.0  # Less than 1 second
    
    def test_correlation_context_performance(self):
        """Test correlation context performance under load."""
        num_operations = 10000
        
        # Test context operations
        start_time = time.perf_counter()
        
        for i in range(num_operations):
            correlation_id = f"perf-test-{i}"
            with CorrelationContext.with_correlation_id(correlation_id):
                # Simulate work within context
                current_id = get_correlation_id()
                assert current_id == correlation_id
        
        duration = time.perf_counter() - start_time
        ops_per_second = num_operations / duration
        
        print(f"Completed {num_operations} context operations in {duration:.4f}s")
        print(f"Performance: {ops_per_second:.0f} operations/second")
        
        # Should handle high throughput
        assert ops_per_second > 10000  # More than 10K ops/second


class TestConcurrentLoggingPerformance:
    """ðŸš€ Concurrent Logging Performance Tests"""
    
    def test_concurrent_unified_logging_performance(self):
        """Test unified logging performance under concurrent load."""
        manager = get_unified_logging_manager()
        num_threads = 10
        operations_per_thread = 50
        
        def worker_thread(thread_id: int) -> Dict[str, Any]:
            thread_start = time.perf_counter()
            operations_completed = 0
            
            for i in range(operations_per_thread):
                try:
                    # Set correlation context for each operation
                    correlation_id = f"thread-{thread_id}-{i}"
                    with CorrelationContext.with_correlation_id(correlation_id):
                        # Log database operation
                        manager.log_database_operation(
                            db_type="qdrant",
                            operation="concurrent_test",
                            duration_ms=float(i % 100),
                            success=True,
                            record_count=i % 10
                        )
                        
                        operations_completed += 1
                except Exception as e:
                    print(f"Thread {thread_id} error: {e}")
            
            thread_duration = time.perf_counter() - thread_start
            return {
                "thread_id": thread_id,
                "operations_completed": operations_completed,
                "duration": thread_duration,
                "ops_per_second": operations_completed / thread_duration if thread_duration > 0 else 0
            }
        
        # Run concurrent workers
        start_time = time.perf_counter()
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = [executor.submit(worker_thread, i) for i in range(num_threads)]
            results = [future.result() for future in as_completed(futures)]
        
        total_duration = time.perf_counter() - start_time
        total_operations = sum(r["operations_completed"] for r in results)
        overall_throughput = total_operations / total_duration
        
        print(f"Concurrent Logging Performance Results:")
        print(f"Total operations: {total_operations}")
        print(f"Total duration: {total_duration:.4f}s")
        print(f"Overall throughput: {overall_throughput:.0f} operations/second")
        
        # Should handle concurrent load efficiently
        assert overall_throughput > 100  # More than 100 ops/second overall


# Performance test fixtures
@pytest.fixture
def clean_performance_state():
    """Fixture ensuring clean performance state."""
    # Clear any existing correlation context
    CorrelationContext.set_correlation_id(None)
    yield
    # Cleanup
    CorrelationContext.set_correlation_id(None)


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
