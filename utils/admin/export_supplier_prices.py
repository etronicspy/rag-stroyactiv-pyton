#!/usr/bin/env python3
"""
–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –ø—Ä–∞–π—Å–æ–≤ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ –≤ CSV —Å –ø–æ–ª–Ω—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏
"""

import sys
import os
import csv
import json
import argparse
from datetime import datetime
from typing import List, Dict, Any, Optional
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue

def get_qdrant_client():
    """–ü–æ–ª—É—á–∏—Ç—å –∫–ª–∏–µ–Ω—Ç Qdrant"""
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env.local
    from dotenv import load_dotenv
    load_dotenv('.env.local')
    
    return QdrantClient(
        url=os.getenv("QDRANT_URL", "http://localhost:6333"),
        api_key=os.getenv("QDRANT_API_KEY")
    )

def get_collection_name(supplier_id: str) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–ª—è –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞"""
    return f"supplier_{supplier_id}_prices"

def export_supplier_prices_to_csv(
    supplier_id: str,
    output_file: Optional[str] = None,
    include_vectors: bool = True,
    vector_format: str = "json",
    limit: Optional[int] = None
) -> str:
    """
    –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∞–π—Å—ã –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ –≤ CSV
    
    Args:
        supplier_id: ID –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞
        output_file: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        include_vectors: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –≤–µ–∫—Ç–æ—Ä—ã –≤ —ç–∫—Å–ø–æ—Ä—Ç
        vector_format: –§–æ—Ä–º–∞—Ç –≤–µ–∫—Ç–æ—Ä–æ–≤ ("json", "columns", "compact")
        limit: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π
    
    Returns:
        –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
    """
    
    print(f"üîÑ –≠–∫—Å–ø–æ—Ä—Ç –ø—Ä–∞–π—Å–∞ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞: {supplier_id}")
    
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Qdrant
    client = get_qdrant_client()
    collection_name = get_collection_name(supplier_id)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏
    try:
        collections = client.get_collections()
        if not any(c.name == collection_name for c in collections.collections):
            print(f"‚ùå –ö–æ–ª–ª–µ–∫—Ü–∏—è '{collection_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return None
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Qdrant: {e}")
        return None
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
    print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏...")
    
    all_points = []
    offset = None
    batch_size = 100
    
    while True:
        try:
            if limit and len(all_points) >= limit:
                all_points = all_points[:limit]
                break
                
            current_limit = min(batch_size, limit - len(all_points)) if limit else batch_size
            
            result = client.scroll(
                collection_name=collection_name,
                limit=current_limit,
                offset=offset,
                with_payload=True,
                with_vectors=include_vectors
            )
            
            if isinstance(result, tuple):
                points, next_offset = result
            else:
                points = result
                next_offset = None
            
            if not points:
                break
                
            all_points.extend(points)
            print(f"   üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(all_points)} –∑–∞–ø–∏—Å–µ–π")
            
            if next_offset is None:
                break
                
            offset = next_offset
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None
    
    if not all_points:
        print("üì≠ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
        return None
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_points)} –∑–∞–ø–∏—Å–µ–π")
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    if not output_file:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        vector_suffix = "_with_vectors" if include_vectors else "_no_vectors"
        output_file = f"export_{supplier_id}_{timestamp}{vector_suffix}.csv"
    
    # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
    sample_point = all_points[0]
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞–Ω–Ω—ã—Ö
    is_extended_format = any(key in sample_point.payload for key in ["sku", "unit_price", "pricelistid"])
    
    print(f"üìä –§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö: {'–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π' if is_extended_format else '–ë–∞–∑–æ–≤—ã–π (legacy)'}")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ CSV
    if is_extended_format:
        base_headers = [
            "id", "name", "sku", "use_category", "upload_date",
            "unit_price", "unit_price_currency", "unit_calc_price", "unit_calc_price_currency",
            "buy_price", "buy_price_currency", "sale_price", "sale_price_currency",
            "calc_unit", "count", "pricelistid", "is_processed", "date_price_change",
            "created", "modified", "supplier_id"
        ]
    else:
        base_headers = [
            "id", "name", "use_category", "unit", "price", "description", 
            "upload_date", "supplier_id"
        ]
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ª–µ–π
    headers = base_headers.copy()
    vector_headers = []
    
    if include_vectors and sample_point.vector:
        if vector_format == "json":
            headers.append("embedding_vector")
        elif vector_format == "columns":
            vector_size = len(sample_point.vector)
            vector_headers = [f"vec_{i:04d}" for i in range(vector_size)]
            headers.extend(vector_headers)
        elif vector_format == "compact":
            headers.extend(["vector_norm", "vector_mean", "vector_std", "vector_min", "vector_max"])
    
    # –ó–∞–ø–∏—Å—å –≤ CSV
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª: {output_file}")
    
    try:
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
            writer.writerow(headers)
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            for i, point in enumerate(all_points, 1):
                if i % 100 == 0:
                    print(f"   üíæ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i}/{len(all_points)} –∑–∞–ø–∏—Å–µ–π")
                
                row = []
                
                # –ë–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
                for header in base_headers:
                    if header == "id":
                        row.append(str(point.id))
                    elif header == "supplier_id":
                        row.append(supplier_id)
                    else:
                        value = point.payload.get(header, "")
                        if value is None:
                            value = ""
                        row.append(str(value))
                
                # –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø–æ–ª—è
                if include_vectors and point.vector:
                    if vector_format == "json":
                        row.append(json.dumps(point.vector))
                    elif vector_format == "columns":
                        row.extend(point.vector)
                    elif vector_format == "compact":
                        import numpy as np
                        vec_array = np.array(point.vector)
                        row.extend([
                            float(np.linalg.norm(vec_array)),  # –Ω–æ—Ä–º–∞
                            float(np.mean(vec_array)),         # —Å—Ä–µ–¥–Ω–µ–µ
                            float(np.std(vec_array)),          # —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
                            float(np.min(vec_array)),          # –º–∏–Ω–∏–º—É–º
                            float(np.max(vec_array))           # –º–∞–∫—Å–∏–º—É–º
                        ])
                elif include_vectors:
                    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –µ—Å–ª–∏ –≤–µ–∫—Ç–æ—Ä –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
                    if vector_format == "json":
                        row.append("")
                    elif vector_format == "columns":
                        row.extend([""] * len(vector_headers))
                    elif vector_format == "compact":
                        row.extend(["", "", "", "", ""])
                
                writer.writerow(row)
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª: {e}")
        return None
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    file_size = os.path.getsize(output_file)
    file_size_mb = file_size / (1024 * 1024)
    
    print("=" * 60)
    print("‚úÖ –≠–ö–°–ü–û–†–¢ –ó–ê–í–ï–†–®–ï–ù")
    print("=" * 60)
    print(f"üìÅ –§–∞–π–ª: {output_file}")
    print(f"üìä –ó–∞–ø–∏—Å–µ–π: {len(all_points)}")
    print(f"üìè –ö–æ–ª–æ–Ω–æ–∫: {len(headers)}")
    print(f"üíæ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size_mb:.2f} MB")
    print(f"üî¢ –§–æ—Ä–º–∞—Ç –≤–µ–∫—Ç–æ—Ä–æ–≤: {vector_format if include_vectors else '–±–µ–∑ –≤–µ–∫—Ç–æ—Ä–æ–≤'}")
    
    if include_vectors and vector_format == "columns":
        print(f"üéØ –†–∞–∑–º–µ—Ä –≤–µ–∫—Ç–æ—Ä–∞: {len(vector_headers)} –∏–∑–º–µ—Ä–µ–Ω–∏–π")
    
    return output_file

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(
        description="–≠–∫—Å–ø–æ—Ä—Ç –ø—Ä–∞–π—Å–æ–≤ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ –≤ CSV —Å –≤–µ–∫—Ç–æ—Ä–∞–º–∏",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

  # –ë–∞–∑–æ–≤—ã–π —ç–∫—Å–ø–æ—Ä—Ç —Å –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –≤ JSON
  python utils/export_supplier_prices.py –°—Ç—Ä–æ–π–¢–æ—Ä–≥_–ú–µ–≥–∞

  # –≠–∫—Å–ø–æ—Ä—Ç –±–µ–∑ –≤–µ–∫—Ç–æ—Ä–æ–≤
  python utils/export_supplier_prices.py –°—Ç—Ä–æ–π–¢–æ—Ä–≥_–ú–µ–≥–∞ --no-vectors

  # –≠–∫—Å–ø–æ—Ä—Ç —Å –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö  
  python utils/export_supplier_prices.py –°—Ç—Ä–æ–π–¢–æ—Ä–≥_–ú–µ–≥–∞ --vector-format columns

  # –≠–∫—Å–ø–æ—Ä—Ç —Å –∫–æ–º–ø–∞–∫—Ç–Ω—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º –≤–µ–∫—Ç–æ—Ä–æ–≤
  python utils/export_supplier_prices.py –°—Ç—Ä–æ–π–¢–æ—Ä–≥_–ú–µ–≥–∞ --vector-format compact

  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç
  python utils/export_supplier_prices.py –°—Ç—Ä–æ–π–¢–æ—Ä–≥_–ú–µ–≥–∞ --limit 100

  # –≠–∫—Å–ø–æ—Ä—Ç –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª
  python utils/export_supplier_prices.py –°—Ç—Ä–æ–π–¢–æ—Ä–≥_–ú–µ–≥–∞ -o my_export.csv
        """
    )
    
    parser.add_argument(
        "supplier_id",
        nargs='?',
        help="ID –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞"
    )
    
    parser.add_argument(
        "-o", "--output",
        help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É CSV —Ñ–∞–π–ª—É (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"
    )
    
    parser.add_argument(
        "--no-vectors",
        action="store_true",
        help="–ò—Å–∫–ª—é—á–∏—Ç—å –≤–µ–∫—Ç–æ—Ä—ã –∏–∑ —ç–∫—Å–ø–æ—Ä—Ç–∞"
    )
    
    parser.add_argument(
        "--vector-format",
        choices=["json", "columns", "compact"],
        default="json",
        help="–§–æ—Ä–º–∞—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: json)"
    )
    
    parser.add_argument(
        "--limit",
        type=int,
        help="–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º—ã—Ö –∑–∞–ø–∏—Å–µ–π"
    )
    
    parser.add_argument(
        "--list-suppliers",
        action="store_true", 
        help="–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤"
    )
    
    args = parser.parse_args()
    
    # –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤
    if args.list_suppliers:
        print("üîç –ü–æ–∏—Å–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤...")
        try:
            client = get_qdrant_client()
            collections = client.get_collections()
            
            supplier_collections = [
                c.name for c in collections.collections 
                if c.name.startswith("supplier_") and c.name.endswith("_prices")
            ]
            
            if supplier_collections:
                print("\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∏:")
                for collection in sorted(supplier_collections):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ –∏–∑ –∏–º–µ–Ω–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
                    supplier_id = collection.replace("supplier_", "").replace("_prices", "")
                    
                    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
                    try:
                        info = client.get_collection(collection)
                        count = info.points_count if hasattr(info, 'points_count') else '?'
                    except:
                        count = '?'
                    
                    print(f"  ‚Ä¢ {supplier_id} ({count} –∑–∞–ø–∏—Å–µ–π)")
            else:
                print("üì≠ –ü–æ—Å—Ç–∞–≤—â–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞: {e}")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ supplier_id —É–∫–∞–∑–∞–Ω –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
    if not args.supplier_id:
        print("‚ùå –û—à–∏–±–∫–∞: –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å ID –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --list-suppliers –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤")
        sys.exit(1)
    
    # –í—ã–ø–æ–ª–Ω–∏—Ç—å —ç–∫—Å–ø–æ—Ä—Ç
    include_vectors = not args.no_vectors
    
    result = export_supplier_prices_to_csv(
        supplier_id=args.supplier_id,
        output_file=args.output,
        include_vectors=include_vectors,
        vector_format=args.vector_format,
        limit=args.limit
    )
    
    if result:
        print(f"\nüéâ –≠–∫—Å–ø–æ—Ä—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω: {result}")
    else:
        print("\nüí• –≠–∫—Å–ø–æ—Ä—Ç –Ω–µ —É–¥–∞–ª—Å—è")
        sys.exit(1)

if __name__ == "__main__":
    main() 