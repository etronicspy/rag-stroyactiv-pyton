import asyncio
import logging
from typing import List, Dict, Any, Optional, Tuple
import numpy as np
from datetime import datetime
from dataclasses import dataclass, asdict
import json

from qdrant_client.models import Distance, VectorParams, PointStruct, Filter, FieldCondition, MatchValue
from core.config import settings
from services.materials_consolidated import MaterialsService  
from services.price_processor import PriceProcessor
from .common import (
    embedding_service, 
    qdrant_service, 
    parallel_processing
)
from .common_utils import (
    calculate_cosine_similarity,
    calculate_cosine_similarity_batch,
    format_confidence,
    generate_unique_id
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MaterialMatch:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤"""
    reference_id: str
    reference_name: str
    reference_use_category: str
    reference_unit: str
    price_item_name: str
    price_item_use_category: str  
    price_item_unit: str
    price_item_price: float
    price_item_supplier: str
    name_similarity: float
    unit_similarity: float
    combined_score: float
    match_confidence: str  # "high", "medium", "low"
    created_at: datetime

class MaterialMatcher:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤"""
    
    def __init__(self):
        self.materials_service = MaterialsService()
        self.price_processor = PriceProcessor()
        
        # –ü–æ—Ä–æ–≥–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        self.HIGH_CONFIDENCE_THRESHOLD = 0.85
        self.MEDIUM_CONFIDENCE_THRESHOLD = 0.70
        self.UNIT_MATCH_WEIGHT = 0.3
        self.NAME_MATCH_WEIGHT = 0.7
        
        # –ö–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        self.matches_collection = "material_matches"
        
    async def _get_embedding(self, text: str) -> List[float]:
        """–ü–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        return await embedding_service.get_embedding(text)

    def _calculate_cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –¥–≤—É–º—è –≤–µ–∫—Ç–æ—Ä–∞–º–∏ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        return calculate_cosine_similarity(vec1, vec2)

    def _determine_confidence(self, score: float) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–∏ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        return format_confidence(score, self.HIGH_CONFIDENCE_THRESHOLD, self.MEDIUM_CONFIDENCE_THRESHOLD)

    async def _get_unit_embedding_cached(self, unit: str) -> List[float]:
        """–ü–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        return await embedding_service.get_embedding(unit)

    async def _ensure_matches_collection_exists(self):
        """–°–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ)"""
        qdrant_service.ensure_collection_exists(self.matches_collection)

    async def get_reference_materials(self) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã"""
        try:
            materials = await self.materials_service.get_materials(limit=1000)
            return [
                {
                    "id": material.id,
                    "name": material.name,
                    "use_category": material.use_category,
                    "unit": material.unit,
                    "description": material.description or "",
                    "embedding": material.embedding
                }
                for material in materials
            ]
        except Exception as e:
            logger.error(f"Error getting reference materials: {e}")
            return []

    def get_price_list_materials_with_embeddings(self, supplier_id: str) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ)"""
        try:
            collection_name = f"supplier_{supplier_id}_prices"
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            if not qdrant_service.collection_exists(collection_name):
                logger.warning(f"Collection {collection_name} not found")
                return []
            
            # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Ç–æ—á–∫–∏ —Å –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –∏ payload
            points = qdrant_service.get_points_with_payload(collection_name, limit=1000)
            
            materials = []
            for point in points:
                materials.append({
                    "id": str(point.id),
                    "name": point.payload.get("name"),
                    "use_category": point.payload.get("use_category", ""), 
                    "unit": point.payload.get("unit"),
                    "price": point.payload.get("price"),
                    "description": point.payload.get("description", ""),
                    "supplier": supplier_id,
                    "embedding": point.vector,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —ç–º–±–µ–¥–¥–∏–Ω–≥
                    "upload_date": point.payload.get("upload_date")
                })
            
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –¥–∞—Ç–µ –∑–∞–≥—Ä—É–∑–∫–∏ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
            materials.sort(key=lambda x: x.get("upload_date", ""), reverse=True)
            
            logger.info(f"Retrieved {len(materials)} materials with embeddings from {collection_name}")
            return materials
            
        except Exception as e:
            logger.error(f"Error getting price list materials with embeddings: {e}")
            return []

    async def match_materials(self, supplier_id: str) -> List[MaterialMatch]:
        """–°–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏–∑ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏ –∏—Å–ø–æ–ª—å–∑—É—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏"""
        logger.info(f"Starting material matching for supplier: {supplier_id}")
        
        # –ü–æ–ª—É—á–∏—Ç—å —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏–∑ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
        reference_materials = await self.get_reference_materials()
        price_materials = self.get_price_list_materials_with_embeddings(supplier_id)
        
        if not reference_materials:
            logger.warning("No reference materials found")
            return []
        
        if not price_materials:
            logger.warning(f"No price materials found for supplier {supplier_id}")
            return []
        
        logger.info(f"Found {len(reference_materials)} reference materials and {len(price_materials)} price materials")
        
        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
        unique_units = set()
        for ref_mat in reference_materials:
            unique_units.add(ref_mat['unit'])
        for price_mat in price_materials:
            unique_units.add(price_mat['unit'])
        
        logger.info(f"Pre-caching embeddings for {len(unique_units)} unique units")
        for unit in unique_units:
            await self._get_unit_embedding_cached(unit)
        
        matches = []
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –∏–∑ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –Ω–∞–π—Ç–∏ –ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–æ–º
        for i, price_item in enumerate(price_materials):
            logger.info(f"Processing price item {i+1}/{len(price_materials)}: {price_item['name']}")
            best_match = None
            best_score = 0.0
            
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –∏–∑ –ø—Ä–∞–π—Å–∞
            price_name_embedding = price_item.get('embedding')
            if not price_name_embedding:
                logger.warning(f"No embedding found for price item: {price_item['name']}")
                continue
                
            # –ü–æ–ª—É—á–∏—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
            price_unit_embedding = await self._get_unit_embedding_cached(price_item['unit'])
            
            # –°—Ä–∞–≤–Ω–∏—Ç—å —Å –∫–∞–∂–¥—ã–º —ç—Ç–∞–ª–æ–Ω–Ω—ã–º –º–∞—Ç–µ—Ä–∏–∞–ª–æ–º
            for ref_material in reference_materials:
                try:
                    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞
                    ref_name_embedding = ref_material.get('embedding')
                    if not ref_name_embedding:
                        logger.warning(f"No embedding found for reference material: {ref_material['name']}")
                        continue
                    
                    # –ü–æ–ª—É—á–∏—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
                    ref_unit_embedding = await self._get_unit_embedding_cached(ref_material['unit'])
                    
                    # –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ö–æ–¥—Å—Ç–≤–æ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∏ –µ–¥–∏–Ω–∏—Ü–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è
                    name_similarity = self._calculate_cosine_similarity(price_name_embedding, ref_name_embedding)
                    unit_similarity = self._calculate_cosine_similarity(price_unit_embedding, ref_unit_embedding)
                    
                    # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—á–µ—Ç —Å –≤–µ—Å–∞–º–∏
                    combined_score = (
                        name_similarity * self.NAME_MATCH_WEIGHT + 
                        unit_similarity * self.UNIT_MATCH_WEIGHT
                    )
                    
                    logger.debug(f"  vs reference {ref_material['name']}: name={name_similarity:.3f}, unit={unit_similarity:.3f}, combined={combined_score:.3f}")
                    
                    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                    if combined_score > best_score:
                        best_score = combined_score
                        best_match = MaterialMatch(
                            reference_id=ref_material.get('id', ''),
                            reference_name=ref_material['name'],
                            reference_use_category=ref_material['use_category'],
                            reference_unit=ref_material['unit'],
                            price_item_name=price_item['name'],
                            price_item_use_category=price_item['use_category'],
                            price_item_unit=price_item['unit'],
                            price_item_price=price_item['price'],
                            price_item_supplier=supplier_id,
                            name_similarity=name_similarity,
                            unit_similarity=unit_similarity,
                            combined_score=combined_score,
                            match_confidence=self._determine_confidence(combined_score),
                            created_at=datetime.utcnow()
                        )
                
                except Exception as e:
                    logger.error(f"Error processing reference material {ref_material.get('name', 'unknown')}: {e}")
                    continue
            
            if best_match:
                matches.append(best_match)
                logger.info(f"Best match for '{price_item['name']}': '{best_match.reference_name}' (score: {best_match.combined_score:.3f}, confidence: {best_match.match_confidence})")
        
        logger.info(f"Found {len(matches)} matches using existing embeddings")
        return matches

    async def match_materials_with_vector_search(self, supplier_id: str, top_k: int = 5) -> List[MaterialMatch]:
        """–°–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏—Å–ø–æ–ª—å–∑—É—è –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ)"""
        logger.info(f"Starting highly optimized material matching for supplier: {supplier_id}")
        
        # –ü–æ–ª—É—á–∏—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏–∑ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
        price_materials = self.get_price_list_materials_with_embeddings(supplier_id)
        
        if not price_materials:
            logger.warning(f"No price materials found for supplier {supplier_id}")
            return []
        
        logger.info(f"Found {len(price_materials)} price materials")
        
        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
        unique_units = set()
        for item in price_materials:
            unique_units.add(item['unit'])
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è
        unit_embeddings_tasks = [self._get_unit_embedding_cached(unit) for unit in unique_units]
        await parallel_processing(unit_embeddings_tasks, max_concurrent=5)
        
        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞
        async def process_material(price_item):
            try:
                price_name_embedding = price_item.get('embedding')
                if not price_name_embedding:
                    logger.warning(f"No embedding found for price item: {price_item['name']}")
                    return None
                
                # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
                search_results = qdrant_service.client.search(
                    collection_name="materials",
                    query_vector=price_name_embedding,
                    limit=top_k,
                    with_payload=True,
                    score_threshold=0.5  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞
                )
                
                if not search_results:
                    return None
                
                # –ü–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –¥–ª—è –ø—Ä–∞–π—Å-–º–∞—Ç–µ—Ä–∏–∞–ª–∞
                price_unit_embedding = await self._get_unit_embedding_cached(price_item['unit'])
                
                best_match = None
                best_score = 0.0
                
                for result in search_results:
                    try:
                        ref_material = result.payload
                        
                        # –ü–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –¥–ª—è —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞
                        ref_unit_embedding = await self._get_unit_embedding_cached(ref_material['unit'])
                        
                        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∫–æ—Ä –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∫–∞–∫ name_similarity
                        name_similarity = result.score
                        
                        # –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ö–æ–¥—Å—Ç–≤–æ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è
                        unit_similarity = self._calculate_cosine_similarity(price_unit_embedding, ref_unit_embedding)
                        
                        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—á–µ—Ç —Å –≤–µ—Å–∞–º–∏
                        combined_score = (
                            name_similarity * self.NAME_MATCH_WEIGHT + 
                            unit_similarity * self.UNIT_MATCH_WEIGHT
                        )
                        
                        if combined_score > best_score:
                            best_score = combined_score
                            best_match = MaterialMatch(
                                reference_id=str(result.id),
                                reference_name=ref_material['name'],
                                reference_use_category=ref_material.get('use_category', ''),
                                reference_unit=ref_material['unit'],
                                price_item_name=price_item['name'],
                                price_item_use_category=price_item['use_category'],
                                price_item_unit=price_item['unit'],
                                price_item_price=price_item['price'],
                                price_item_supplier=supplier_id,
                                name_similarity=name_similarity,
                                unit_similarity=unit_similarity,
                                combined_score=combined_score,
                                match_confidence=self._determine_confidence(combined_score),
                                created_at=datetime.utcnow()
                            )
                    
                    except Exception as e:
                        logger.error(f"Error processing search result: {e}")
                        continue
                
                return best_match
                    
            except Exception as e:
                logger.error(f"Error in vector search for '{price_item['name']}': {e}")
                return None
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
        logger.info("Starting parallel processing of materials...")
        processing_tasks = [process_material(item) for item in price_materials]
        match_results = await parallel_processing(processing_tasks, max_concurrent=8)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º None —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        matches = [match for match in match_results if match is not None]
        
        logger.info(f"Found {len(matches)} matches using highly optimized vector search")
        return matches

    async def save_matches_to_collection(self, matches: List[MaterialMatch]) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é Qdrant (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ)"""
        try:
            await self._ensure_matches_collection_exists()
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ç–µ–∫—Å—Ç—ã –¥–ª—è –±–∞—Ç—á–µ–≤–æ–≥–æ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            match_texts = []
            for match in matches:
                match_text = f"{match.reference_name} {match.price_item_name} {match.reference_use_category} {match.price_item_use_category}"
                match_texts.append(match_text)
            
            # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∑–∞ –æ–¥–∏–Ω —Ä–∞–∑
            match_embeddings = await embedding_service.get_embeddings_batch(match_texts)
            
            # –°–æ–∑–¥–∞—Ç—å —Ç–æ—á–∫–∏
            points = []
            for i, (match, embedding) in enumerate(zip(matches, match_embeddings)):
                point_id = generate_unique_id(match_texts[i], "MATCH_")
                
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å payload —Å —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                payload = asdict(match)
                payload['created_at'] = match.created_at.isoformat()
                
                point = PointStruct(
                    id=point_id,
                    vector=embedding,
                    payload=payload
                )
                points.append(point)
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –±–∞—Ç—á–∞—Ö
            success = qdrant_service.upsert_points_batch(self.matches_collection, points)
            
            if success:
                logger.info(f"Saved {len(matches)} matches to collection {self.matches_collection}")
            return success
            
        except Exception as e:
            logger.error(f"Error saving matches to collection: {e}")
            return False

    def get_matches_by_supplier(self, supplier_id: str, confidence_filter: Optional[str] = None) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ)"""
        try:
            filter_conditions = [
                FieldCondition(key="price_item_supplier", match=MatchValue(value=supplier_id))
            ]
            
            if confidence_filter:
                filter_conditions.append(
                    FieldCondition(key="match_confidence", match=MatchValue(value=confidence_filter))
                )
            
            search_filter = Filter(must=filter_conditions)
            
            results = qdrant_service.client.scroll(
                collection_name=self.matches_collection,
                scroll_filter=search_filter,
                limit=1000
            )
            
            matches = [point.payload for point in results[0]]
            return matches
            
        except Exception as e:
            logger.error(f"Error getting matches for supplier {supplier_id}: {e}")
            return []

    async def generate_matches_report(self, supplier_id: str) -> Dict[str, Any]:
        """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç –ø–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—é –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤"""
        matches = self.get_matches_by_supplier(supplier_id)
        
        if not matches:
            return {
                "supplier_id": supplier_id,
                "total_matches": 0,
                "matches": [],
                "statistics": {
                    "high_confidence": 0,
                    "medium_confidence": 0,  
                    "low_confidence": 0,
                    "average_score": 0.0
                }
            }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        high_conf = len([m for m in matches if m["match_confidence"] == "high"])
        medium_conf = len([m for m in matches if m["match_confidence"] == "medium"])
        low_conf = len([m for m in matches if m["match_confidence"] == "low"])
        avg_score = sum(m["combined_score"] for m in matches) / len(matches)
        
        return {
            "supplier_id": supplier_id,
            "total_matches": len(matches),
            "matches": matches,
            "statistics": {
                "high_confidence": high_conf,
                "medium_confidence": medium_conf,
                "low_confidence": low_conf,
                "average_score": round(avg_score, 3)
            }
        }

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã"""
    matcher = MaterialMatcher()
    
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è - —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–ª—è –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞
    supplier_id = "–ü–æ—Å—Ç–∞–≤—â–∏–∫_–°—Ç—Ä–æ–π_–ú–∞—Ç–µ—Ä–∏–∞–ª—ã"
    
    print(f"üîç –ù–∞—á–∏–Ω–∞—é —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –¥–ª—è –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞: {supplier_id}")
    print("\nüöÄ –ú–µ—Ç–æ–¥ 1: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º –ø–æ–∏—Å–∫–æ–º")
    
    # –í—ã–ø–æ–ª–Ω–∏—Ç—å –±—ã—Å—Ç—Ä–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º –ø–æ–∏—Å–∫–æ–º
    matches_fast = await matcher.match_materials_with_vector_search(supplier_id, top_k=3)
    
    if matches_fast:
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(matches_fast)} –±—ã—Å—Ç—Ä—ã—Ö —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π")
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é
        if await matcher.save_matches_to_collection(matches_fast):
            print("üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é")
        
        # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç
        report = await matcher.generate_matches_report(supplier_id)
        
        print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–´–°–¢–†–û–ì–û –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–Ø:")
        print(f"   –í—Å–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {report['total_matches']}")
        print(f"   –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {report['statistics']['high_confidence']}")
        print(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {report['statistics']['medium_confidence']}")
        print(f"   –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {report['statistics']['low_confidence']}")
        print(f"   –°—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä: {report['statistics']['average_score']}")
        
        print("\nüéØ –õ–£–ß–®–ò–ï –°–û–í–ü–ê–î–ï–ù–ò–Ø (–í–ï–ö–¢–û–†–ù–´–ô –ü–û–ò–°–ö):")
        high_confidence_matches = [m for m in matches_fast if m.match_confidence == "high"]
        for match in high_confidence_matches[:5]:  # –ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ø-5
            print(f"   ‚Ä¢ {match.price_item_name} ‚Üí {match.reference_name}")
            print(f"     –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {match.price_item_use_category} ‚Üí {match.reference_use_category}")
            print(f"     –ï–¥–∏–Ω–∏—Ü—ã: {match.price_item_unit} ‚Üí {match.reference_unit}")
            print(f"     –°–∫–æ—Ä: {match.combined_score:.3f}, –¶–µ–Ω–∞: {match.price_item_price}‚ÇΩ")
            print()
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –≤ JSON
        with open(f"matches_report_fast_{supplier_id}.json", "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        print(f"üìÑ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ matches_report_fast_{supplier_id}.json")
        
        print("\n" + "="*60)
        print("‚ö° –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –° –≠–ú–ë–ï–î–î–ò–ù–ì–ê–ú–ò –ó–ê–í–ï–†–®–ï–ù–ê")
        print("="*60)
        print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü")
        print(f"üöÄ –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ Qdrant –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è")  
        print(f"üß† –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è")
        print(f"üìà –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º –∏ –µ–¥–∏–Ω–∏—Ü–∞–º")
        
    else:
        print("‚ùå –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

if __name__ == "__main__":
    asyncio.run(main()) 