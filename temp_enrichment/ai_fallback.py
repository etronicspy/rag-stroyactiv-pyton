#!/usr/bin/env python3
"""
AI Fallback –º–æ–¥—É–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ª–æ–∂–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å regex –ø–∞—Ä—Å–µ—Ä.
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞—Ç—Ä–∞—Ç –Ω–∞ API –∑–∞–ø—Ä–æ—Å—ã.
"""

import json, os, time, hashlib, yaml
from typing import Optional, Dict, Any, List, Tuple
import openai
from dataclasses import dataclass
from packaging import version


@dataclass
class AIParseResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–≤–∞—Ä–∞ —á–µ—Ä–µ–∑ AI"""
    metric_unit: str
    price_coefficient: float
    parsing_method: str = "ai_fallback"
    confidence: float = 0.85


class AIFallbackParser:
    """AI –ø–∞—Ä—Å–µ—Ä –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –∑–∞–ø—Ä–æ—Å–æ–≤"""
    
    def __init__(self, api_key: Optional[str] = None, cache_file: str = "ai_cache.json"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI –ø–∞—Ä—Å–µ—Ä–∞
        
        Args:
            api_key: OpenAI API –∫–ª—é—á (–µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è)
            cache_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–µ—à–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("OpenAI API key not found. Set OPENAI_API_KEY environment variable or pass api_key parameter")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è openai "legacy" (< 1.0)
        self._use_legacy_client = version.parse(openai.__version__) < version.parse("1.0.0")

        if self._use_legacy_client:
            # –°—Ç–∞—Ä—ã–π (<1.0) –∫–ª–∏–µ–Ω—Ç
            openai.api_key = self.api_key
            self._client = openai  # type: ignore
        else:
            # –ù–æ–≤—ã–π (>=1.0) –∫–ª–∏–µ–Ω—Ç
            try:
                from openai import OpenAI  # type: ignore
            except ImportError as exc:
                raise ImportError("OpenAI >=1.0 detected but 'OpenAI' class not found") from exc

            self._client = OpenAI(api_key=self.api_key)  # pylint: disable=not-callable
        self.cost_per_token = 0.0015 / 1000  # GPT-3.5-turbo —Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞ —Ç–æ–∫–µ–Ω
        self.total_cost = 0.0
        self.total_requests = 0
        self.total_tokens = 0
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤
        self._prompts = self._load_prompts()
        
        # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.cache_file = cache_file
        self.cache = self._load_cache()
        
        # –ë–∞—Ç—á–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–æ–≤
        self.batch_size = 5  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –æ–¥–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ
        self.batch_queue = []
    
    def _load_prompts(self, path: str = "prompts.yaml") -> Dict[str, str]:
        """–ß–∏—Ç–∞–µ—Ç YAML —Å —à–∞–±–ª–æ–Ω–∞–º–∏ –ø—Ä–æ–º–ø—Ç–æ–≤."""
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                return yaml.safe_load(f)
        # fallback: –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã
        return {
            "system": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–º –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º.",
            "single": "–¢–û–í–ê–†: {name}\n–¶–ï–ù–ê: {price} {unit}",
            "batch_intro": "–¢–æ–≤–∞—Ä—ã:",
            "batch_item": "{idx}. {name} - {price} {unit}",
        }
    
    def _load_cache(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–µ—à –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"Warning: Could not load cache: {str(e)}")
        return {}
    
    def _save_cache(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–µ—à –≤ —Ñ–∞–π–ª"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"Warning: Could not save cache: {str(e)}")
    
    def _get_cache_key(self, name: str, price: float, unit: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –∫–µ—à–∞ –¥–ª—è —Ç–æ–≤–∞—Ä–∞"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ö–µ—à –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ–≤–∞—Ä–∞
        data = f"{name.lower()}|{price}|{unit.lower()}"
        return hashlib.md5(data.encode('utf-8')).hexdigest()
    
    def parse_product(self, name: str, price: float, unit: str) -> Optional[AIParseResult]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–≤–∞—Ä–∞ —á–µ—Ä–µ–∑ AI
        
        Args:
            name: –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
            price: –¶–µ–Ω–∞
            unit: –ï–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è
            
        Returns:
            AIParseResult –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, None –µ—Å–ª–∏ –Ω–µ—É–¥–∞—á–Ω–æ
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
        cache_key = self._get_cache_key(name, price, unit)
        if cache_key in self.cache:
            cached_result = self.cache[cache_key]
            return AIParseResult(
                metric_unit=cached_result['metric_unit'],
                price_coefficient=cached_result['price_coefficient'],
                confidence=cached_result.get('confidence', 0.85)
            )
        
        try:
            # –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ OpenAI
            prompt = self._create_prompt(name, price, unit)
            
            response = self._chat_completion([
                {"role": "system", "content": self._prompts["system"]},
                {"role": "user", "content": prompt}
            ], 100)
            
            # –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self._update_stats(response)
            
            # –ü–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç
            result = self._parse_ai_response(response.choices[0].message.content, name, price, unit)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à
            if result:
                self.cache[cache_key] = {
                    'metric_unit': result.metric_unit,
                    'price_coefficient': result.price_coefficient,
                    'confidence': result.confidence
                }
                self._save_cache()
            
            return result
            
        except Exception as e:
            print(f"‚ùå AI parsing error for '{name}': {str(e)}")
            return None
    
    def parse_batch(self, products: List[Dict]) -> List[Tuple[Dict, Optional[AIParseResult]]]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ —Ç–æ–≤–∞—Ä–æ–≤ —á–µ—Ä–µ–∑ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –∫ AI
        
        Args:
            products: –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{"name": str, "price": float, "unit": str}, ...]
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (—Ç–æ–≤–∞—Ä, —Ä–µ–∑—É–ª—å—Ç–∞—Ç)
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à –¥–ª—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤
        uncached_products = []
        results = []
        
        for product in products:
            name = product.get('name', '')
            price = float(product.get('price', 0))
            unit = product.get('unit', '—à—Ç')
            
            cache_key = self._get_cache_key(name, price, unit)
            if cache_key in self.cache:
                cached_result = self.cache[cache_key]
                result = AIParseResult(
                    metric_unit=cached_result['metric_unit'],
                    price_coefficient=cached_result['price_coefficient'],
                    confidence=cached_result.get('confidence', 0.85)
                )
                results.append((product, result))
            else:
                uncached_products.append(product)
                results.append((product, None))
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ–∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        if uncached_products:
            try:
                # –°–æ–∑–¥–∞–µ–º –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –¥–ª—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤
                batch_prompt = self._create_batch_prompt(uncached_products)
                
                response = self._chat_completion([
                    {"role": "system", "content": self._prompts["system"]},
                    {"role": "user", "content": batch_prompt}
                ], 500)
                
                # –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                self._update_stats(response)
                
                # –ü–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç –¥–ª—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤
                batch_results = self._parse_batch_response(response.choices[0].message.content, uncached_products)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –∫–µ—à
                for i, product in enumerate(uncached_products):
                    if i < len(batch_results) and batch_results[i]:
                        name = product.get('name', '')
                        price = float(product.get('price', 0))
                        unit = product.get('unit', '—à—Ç')
                        
                        cache_key = self._get_cache_key(name, price, unit)
                        self.cache[cache_key] = {
                            'metric_unit': batch_results[i].metric_unit,
                            'price_coefficient': batch_results[i].price_coefficient,
                            'confidence': batch_results[i].confidence
                        }
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –æ–±—â–µ–º —Å–ø–∏—Å–∫–µ
                        for j, (orig_product, _) in enumerate(results):
                            if orig_product.get('name') == name:
                                results[j] = (orig_product, batch_results[i])
                                break
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–µ—à
                self._save_cache()
                
            except Exception as e:
                print(f"‚ùå AI batch parsing error: {str(e)}")
        
        return results
    
    def _create_prompt(self, name: str, price: float, unit: str) -> str:
        """–°–æ–∑–¥–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è AI"""
        return self._prompts["single"].format(name=name, price=price, unit=unit)
    
    def _create_batch_prompt(self, products: List[Dict]) -> str:
        """–°–æ–∑–¥–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –±–∞—Ç—á–∞ —Ç–æ–≤–∞—Ä–æ–≤"""
        intro = self._prompts["batch_intro"].strip() + "\n"
        products_text = intro
        for i, product in enumerate(products):
            name = product.get('name', '')
            price = float(product.get('price', 0))
            unit = product.get('unit', '—à—Ç')
            item_fmt = self._prompts["batch_item"].format(idx=i+1, name=name, price=price, unit=unit)
            products_text += item_fmt + "\n"
        return products_text
    
    def _parse_ai_response(self, response: str, name: str, price: float, unit: str) -> Optional[AIParseResult]:
        """–ü–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç AI"""
        try:
            # –ò–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if not json_match:
                return None
                
            json_str = json_match.group()
            data = json.loads(json_str)
            
            # –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ
            metric_unit = data.get('metric_unit', '').strip()
            price_coefficient = float(data.get('price_coefficient', 0))
            
            if not metric_unit or price_coefficient <= 0:
                return None
            
            return AIParseResult(
                metric_unit=metric_unit,
                price_coefficient=price_coefficient,
                confidence=0.85
            )
            
        except (json.JSONDecodeError, ValueError, KeyError) as e:
            print(f"‚ùå AI response parsing error: {str(e)}")
            return None
    
    def _parse_batch_response(self, response: str, products: List[Dict]) -> List[Optional[AIParseResult]]:
        """–ü–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç AI –¥–ª—è –±–∞—Ç—á–∞ —Ç–æ–≤–∞—Ä–æ–≤"""
        try:
            # –ò–∑–≤–ª–µ—á—å JSON-–º–∞—Å—Å–∏–≤ –∏–∑ –æ—Ç–≤–µ—Ç–∞
            import re
            json_match = re.search(r'\[.*\]', response, re.DOTALL)
            if not json_match:
                return [None] * len(products)
                
            json_str = json_match.group()
            data_list = json.loads(json_str)
            
            results = []
            allowed_units = {"–º3", "–º2", "–∫–≥", "–ª", "–º"}
            for i, data in enumerate(data_list):
                if i >= len(products):
                    break

                # –ï—Å–ª–∏ —ç–ª–µ–º–µ–Ω—Ç None –∏–ª–∏ –Ω–µ —Å–ª–æ–≤–∞—Ä—å ‚Äî —Å—á–∏—Ç–∞–µ–º –Ω–µ—É–¥–∞—á–Ω—ã–º
                if not isinstance(data, dict):
                    results.append(None)
                    continue

                metric_unit_raw = data.get("metric_unit")
                price_coef_raw = data.get("price_coefficient")

                try:
                    metric_unit = str(metric_unit_raw).strip() if metric_unit_raw is not None else ""
                except Exception:
                    metric_unit = ""

                try:
                    price_coefficient = float(price_coef_raw)
                except Exception:
                    price_coefficient = 0.0

                valid = metric_unit in allowed_units and price_coefficient > 0

                if not valid:
                    results.append(None)
                else:
                    results.append(
                        AIParseResult(
                            metric_unit=metric_unit,
                            price_coefficient=price_coefficient,
                            confidence=0.85,
                        )
                    )
            
            # –î–æ–±–∞–≤–ª—è–µ–º None –¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Ç–æ–≤–∞—Ä–æ–≤, –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–µ–ø–æ–ª–Ω—ã–π
            while len(results) < len(products):
                results.append(None)
                
            return results
            
        except (json.JSONDecodeError, ValueError, KeyError) as e:
            print(f"‚ùå AI batch response parsing error: {str(e)}")
            return [None] * len(products)
    
    def _update_stats(self, response):
        """–û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è AI"""
        self.total_requests += 1
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω—ã –∏–∑ –æ—Ç–≤–µ—Ç–∞, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
        if hasattr(response, 'usage') and hasattr(response.usage, 'total_tokens'):
            tokens = response.usage.total_tokens
        else:
            tokens = 150  # –ü—Ä–∏–º–µ—Ä–Ω–æ 150 —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –∑–∞–ø—Ä–æ—Å
            
        self.total_tokens += tokens
        request_cost = tokens * self.cost_per_token
        self.total_cost += request_cost
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è AI"""
        return {
            "total_requests": self.total_requests,
            "total_tokens": self.total_tokens,
            "total_cost_usd": self.total_cost,
            "total_cost_rub": self.total_cost * 75,  # –ü—Ä–∏–º–µ—Ä–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞
            "cost_per_request_rub": (self.total_cost * 75) / max(1, self.total_requests),
            "cache_size": len(self.cache)
        }

    # ---------------------------------------------------------------------
    # Internal helpers for compatibility with openai <1.0 and >=1.0
    # ---------------------------------------------------------------------

    def _chat_completion(self, messages: List[Dict[str, str]], max_tokens: int) -> Any:  # noqa: ANN401
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç chat completion —Å —É—á—ë—Ç–æ–º –≤–µ—Ä—Å–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞."""
        if self._use_legacy_client:
            return self._client.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=messages,
                max_tokens=max_tokens,
                temperature=0.1,
            )

        # –ù–æ–≤—ã–π –∫–ª–∏–µ–Ω—Ç
        return self._client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=max_tokens,
            temperature=0.1,
        )


class HybridParser:
    """–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–∞—Ä—Å–µ—Ä: regex + AI fallback"""
    
    def __init__(self, regex_parser, ai_parser: Optional[AIFallbackParser] = None):
        """
        Args:
            regex_parser: –û—Å–Ω–æ–≤–Ω–æ–π regex –ø–∞—Ä—Å–µ—Ä
            ai_parser: AI –ø–∞—Ä—Å–µ—Ä –¥–ª—è fallback (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π)
        """
        self.regex_parser = regex_parser
        self.ai_parser = ai_parser
        self.stats = {
            "regex_success": 0,
            "ai_fallback": 0,
            "total_failed": 0
        }
        
        # –û—á–µ—Ä–µ–¥—å –¥–ª—è –±–∞—Ç—á–∏–Ω–≥–∞
        self.batch_queue = []
        self.batch_size = 5  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
    
    def parse_product(self, name: str, price: float, unit: str) -> Dict:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–≤–∞—Ä–∞ —á–µ—Ä–µ–∑ –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥
        
        1. –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è regex –ø–∞—Ä—Å–µ—Ä–æ–º
        2. –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å - –∏—Å–ø–æ–ª—å–∑—É–µ–º AI fallback
        """
        # –ü–æ–ø—ã—Ç–∫–∞ 1: Regex –ø–∞—Ä—Å–µ—Ä
        result = self.regex_parser.parse_product(name, price, unit)
        
        if result.parsing_method != 'no_parsing':
            self.stats["regex_success"] += 1
            return self._convert_to_dict(result)
        
        # –ü–æ–ø—ã—Ç–∫–∞ 2: AI fallback
        if self.ai_parser:
            ai_result = self.ai_parser.parse_product(name, price, unit)
            if ai_result:
                self.stats["ai_fallback"] += 1
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å AI —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –µ–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                return self._convert_ai_to_dict(ai_result, name, price, unit)
        
        # –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å
        self.stats["total_failed"] += 1
        return self._convert_to_dict(result)
    
    def parse_batch(self, products: List[Dict]) -> List[Dict]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ —Ç–æ–≤–∞—Ä–æ–≤ —á–µ—Ä–µ–∑ –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥
        
        Args:
            products: –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{"name": str, "price": float, "unit": str}, ...]
            
        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
        """
        results = []
        ai_fallback_products = []
        
        # –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —Ç–æ–≤–∞—Ä—ã —á–µ—Ä–µ–∑ regex
        for product in products:
            name = product.get('name', '')
            price = float(product.get('price', 0))
            unit = product.get('unit', '—à—Ç')
            
            result = self.regex_parser.parse_product(name, price, unit)
            
            if result.parsing_method != 'no_parsing':
                self.stats["regex_success"] += 1
                results.append(self._convert_to_dict(result))
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è AI fallback
                ai_fallback_products.append(product)
                # –í—Ä–µ–º–µ–Ω–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ—É–¥–∞—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                results.append(self._convert_to_dict(result))
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–≤–∞—Ä—ã –¥–ª—è AI fallback –∏ AI –ø–∞—Ä—Å–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω
        if ai_fallback_products and self.ai_parser:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á —á–µ—Ä–µ–∑ AI
            ai_results = self.ai_parser.parse_batch(ai_fallback_products)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for product, ai_result in ai_results:
                name = product.get('name', '')
                price = float(product.get('price', 0))
                unit = product.get('unit', '—à—Ç')
                
                if ai_result:
                    self.stats["ai_fallback"] += 1
                    # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
                    for i, result in enumerate(results):
                        if result['original_name'] == name:
                            results[i] = self._convert_ai_to_dict(ai_result, name, price, unit)
                            break
                else:
                    self.stats["total_failed"] += 1
        
        return results
    
    def _convert_to_dict(self, parsed_product) -> Dict:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç ParsedProduct –≤ —Å–ª–æ–≤–∞—Ä—å"""
        
        return {
            'original_name': parsed_product.original_name,
            'original_price': parsed_product.original_price,
            'original_unit': parsed_product.original_unit,
            'metric_unit': parsed_product.metric_unit,
            'quantity': parsed_product.quantity,
            'price_per_unit': parsed_product.price_per_unit,
            'price_coefficient': parsed_product.price_coefficient,
            'parsing_method': parsed_product.parsing_method,
            'confidence': parsed_product.confidence
        }
    
    def _convert_ai_to_dict(self, ai_result: AIParseResult, name: str, price: float, unit: str) -> Dict:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å AI —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –µ–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        
        quantity = ai_result.price_coefficient
        price_per_unit = price / quantity if quantity > 0 else price
        
        return {
            'original_name': name,
            'original_price': price,
            'original_unit': unit,
            'metric_unit': ai_result.metric_unit,
            'quantity': quantity,
            'price_per_unit': price_per_unit,
            'price_coefficient': quantity,
            'parsing_method': ai_result.parsing_method,
            'confidence': ai_result.confidence
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞"""
        total = sum(self.stats.values())
        stats = {
            "total_products": total,
            "regex_success": self.stats["regex_success"],
            "ai_fallback": self.stats["ai_fallback"],
            "total_failed": self.stats["total_failed"],
            "regex_success_rate": self.stats["regex_success"] / max(1, total) * 100,
            "ai_fallback_rate": self.stats["ai_fallback"] / max(1, total) * 100,
            "total_success_rate": (self.stats["regex_success"] + self.stats["ai_fallback"]) / max(1, total) * 100
        }
        
        # –î–æ–±–∞–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É AI, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
        if self.ai_parser:
            stats["ai_stats"] = self.ai_parser.get_stats()
        
        return stats


def main():
    """–¢–µ—Å—Ç–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import json
    from regex_parser import RegexParser
    
    # –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    with open('price_sample.json', 'r', encoding='utf-8') as f:
        products = json.load(f)
    
    # –°–æ–∑–¥–∞—Ç—å –ø–∞—Ä—Å–µ—Ä—ã
    regex_parser = RegexParser()
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å AI
    ai_parser = None
    if os.getenv('OPENAI_API_KEY'):
        try:
            ai_parser = AIFallbackParser()
            print("‚úÖ AI fallback –ø–∞—Ä—Å–µ—Ä –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            print(f"‚ö†Ô∏è AI fallback –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {str(e)}")
    else:
        print("‚ö†Ô∏è AI fallback –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –Ω–µ—Ç OPENAI_API_KEY")
    
    # –°–æ–∑–¥–∞—Ç—å –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–∞—Ä—Å–µ—Ä
    hybrid_parser = HybridParser(regex_parser, ai_parser)
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä—Å–µ—Ä
    results = []
    
    # –ë–∞—Ç—á–∏–Ω–≥ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
    batch_size = 5
    for i in range(0, len(products), batch_size):
        batch = products[i:i+batch_size]
        batch_results = hybrid_parser.parse_batch(batch)
        results.extend(batch_results)
        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω –±–∞—Ç—á {i//batch_size + 1}/{(len(products) + batch_size - 1)//batch_size}")
    
    # –í—ã–≤–µ—Å—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = hybrid_parser.get_stats()
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"–í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {stats['total_products']}")
    print(f"Regex —É—Å–ø–µ—à–Ω–æ: {stats['regex_success']} ({stats['regex_success_rate']:.1f}%)")
    print(f"AI fallback: {stats['ai_fallback']} ({stats['ai_fallback_rate']:.1f}%)")
    print(f"–ù–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['total_failed']} ({100 - stats['total_success_rate']:.1f}%)")
    print(f"–û–±—â–∏–π —É—Å–ø–µ—Ö: {stats['total_success_rate']:.1f}%")
    
    if 'ai_stats' in stats:
        ai_stats = stats['ai_stats']
        print(f"\nüí∞ AI –≠–ö–û–ù–û–ú–ò–ö–ê:")
        print(f"–ó–∞–ø—Ä–æ—Å–æ–≤ –∫ AI: {ai_stats['total_requests']}")
        print(f"–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {ai_stats['total_tokens']}")
        print(f"–ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: {ai_stats['total_cost_rub']:.2f} ‚ÇΩ")
        print(f"–°—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞ –∑–∞–ø—Ä–æ—Å: {ai_stats['cost_per_request_rub']:.2f} ‚ÇΩ")
        print(f"–†–∞–∑–º–µ—Ä –∫–µ—à–∞: {ai_stats['cache_size']} —Ç–æ–≤–∞—Ä–æ–≤")
    
    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    with open('ai_fallback_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: ai_fallback_results.json")


if __name__ == "__main__":
    main() 